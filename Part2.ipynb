{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8edf087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "uri = os.getenv(\"URI\")\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d286000",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HADOOP_HOME\"] = \"C:/Hadoop/hadoop-3.3.1\"\n",
    "os.environ[\"PYSPARK_HADOOP_VERSION\"] = \"without\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6484b5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_5628\\2193267402.py:2: DeprecationWarning: The asyncore module is deprecated and will be removed in Python 3.12. The recommended replacement is asyncio\n",
      "  import asyncore\n"
     ]
    }
   ],
   "source": [
    "# Connecting to Cassandra\n",
    "import asyncore\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['localhost'], port=9042)\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e389be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkCassandraApp').\\\n",
    "    config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.5.1').\\\n",
    "    config('spark.cassandra.connection.host', 'localhost').\\\n",
    "    config('spark.sql.extensions', 'com.datastax.spark.connector.CassandraSparkExtensions').\\\n",
    "    config('spark.sql.catalog.mycatalog', 'com.datastax.spark.connector.datasource.CassandraCatalog').\\\n",
    "    config('spark.cassandra.connection.port', '9042').getOrCreate()\n",
    "# Some warnings are to be expected.\n",
    "# If running this cell does not give any output after ~30 seconds, there is likely an error in the configuration (JAVA_HOME, HADOOP_HOME, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bc8d700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x12017e85a10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"CREATE KEYSPACE IF NOT EXISTS my_first_keyspace WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 };\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4268670a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x120379ac890>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new table (first time only)\n",
    "session.set_keyspace('my_first_keyspace')\n",
    "session.execute(\"DROP TABLE IF EXISTS my_first_keyspace.my_first_table;\") # Starting from scratch every time\n",
    "session.execute(\"CREATE TABLE IF NOT EXISTS my_first_table (ind int PRIMARY KEY, company text, model text);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47109c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x120379d4810>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert some data (ind is the primary key, must be unique)\n",
    "session.execute(\"INSERT INTO my_first_table (ind, company, model) VALUES (1, 'Tesla', 'Model S');\")\n",
    "session.execute(\"INSERT INTO my_first_table (ind, company, model) VALUES (2, 'Tesla', 'Model 3');\")\n",
    "session.execute(\"INSERT INTO my_first_table (ind, company, model) VALUES (3, 'Polestar', '3');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "627b927f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(ind=1, company='Tesla', model='Model S')\n",
      "Row(ind=2, company='Tesla', model='Model 3')\n",
      "Row(ind=3, company='Polestar', model='3')\n"
     ]
    }
   ],
   "source": [
    "# Query the data\n",
    "rows = session.execute(\"SELECT * FROM my_first_table;\")\n",
    "for i in rows:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecac6d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ResponseFuture: query='<SimpleStatement query=\"INSERT INTO my_first_table (ind, company, model) VALUES (5, 'Volkswagen', 'ID.3');\", consistency=Not Set>' request_id=25 result=(no result yet) exception=None coordinator_host=None>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute_async(\"INSERT INTO my_first_table (ind, company, model) VALUES (5, 'Volkswagen', 'ID.3');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986b15c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(ind=5, company='Volkswagen', model='ID.3')\n",
      "Row(ind=1, company='Tesla', model='Model S')\n",
      "Row(ind=2, company='Tesla', model='Model 3')\n",
      "Row(ind=3, company='Polestar', model='3')\n"
     ]
    }
   ],
   "source": [
    "# Query the data\n",
    "rows = session.execute(\"SELECT * FROM my_first_table;\")\n",
    "for i in rows:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "125b046c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(ind=1, company='Tesla', model='Model S')\n",
      "Row(ind=2, company='Tesla', model='Model 3')\n"
     ]
    }
   ],
   "source": [
    "# More specific query\n",
    "prepared_statement = session.prepare(\"SELECT * FROM my_first_table WHERE company=? ALLOW FILTERING;\")\n",
    "teslas = session.execute(prepared_statement, ['Tesla'])\n",
    "for i in teslas:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec426148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a database and a collection.\n",
    "database = client['example']\n",
    "collection = database['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dcd52ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x12037337380>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inserting a single document (dictionary).\n",
    "collection.insert_one({'name': 'Hallvard', 'age': 23})\n",
    "\n",
    "# Inserting multiple documents (list of dictionaries).\n",
    "collection.insert_many([\n",
    "    {'name': 'Kristian', 'age': 27},\n",
    "    {'name': 'Ihn Duck', 'age': 15}\n",
    "])\n",
    "\n",
    "# Note that an _id field is automatically generated by MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1687241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('68f24cb2a6f0e9d0a1f97b7f'), 'name': 'Hallvard Lavik', 'age': 33}\n",
      "{'_id': ObjectId('68f24cb2a6f0e9d0a1f97b80'), 'name': 'Kristian', 'age': 37}\n",
      "{'_id': ObjectId('68f24cb2a6f0e9d0a1f97b81'), 'name': 'Ihn Duck', 'age': 25}\n",
      "{'_id': ObjectId('68f25da8d8698bfd0c7e6a7b'), 'name': 'Hallvard Lavik', 'age': 32}\n",
      "{'_id': ObjectId('68f25da8d8698bfd0c7e6a7c'), 'name': 'Kristian', 'age': 36}\n",
      "{'_id': ObjectId('68f25da8d8698bfd0c7e6a7d'), 'name': 'Ihn Duck', 'age': 24}\n",
      "{'_id': ObjectId('68f9e1224e8c45d5ee0fb385'), 'name': 'Hallvard Lavik', 'age': 31}\n",
      "{'_id': ObjectId('68f9e1224e8c45d5ee0fb386'), 'name': 'Kristian', 'age': 35}\n",
      "{'_id': ObjectId('68f9e1224e8c45d5ee0fb387'), 'name': 'Ihn Duck', 'age': 23}\n",
      "{'_id': ObjectId('68f9e24dd4c233458872dfec'), 'name': 'Hallvard Lavik', 'age': 30}\n",
      "{'_id': ObjectId('68f9e24ed4c233458872dfed'), 'name': 'Kristian', 'age': 34}\n",
      "{'_id': ObjectId('68f9e24ed4c233458872dfee'), 'name': 'Ihn Duck', 'age': 22}\n",
      "{'_id': ObjectId('68f9e32c6dfbcb4154919b7f'), 'name': 'Hallvard Lavik', 'age': 29}\n",
      "{'_id': ObjectId('68f9e32c6dfbcb4154919b80'), 'name': 'Kristian', 'age': 33}\n",
      "{'_id': ObjectId('68f9e32c6dfbcb4154919b81'), 'name': 'Ihn Duck', 'age': 21}\n",
      "{'_id': ObjectId('68f9e39db49180ad8f0ac0d1'), 'name': 'Hallvard Lavik', 'age': 28}\n",
      "{'_id': ObjectId('68f9e39db49180ad8f0ac0d2'), 'name': 'Kristian', 'age': 32}\n",
      "{'_id': ObjectId('68f9e39db49180ad8f0ac0d3'), 'name': 'Ihn Duck', 'age': 20}\n",
      "{'_id': ObjectId('68f9e59cd5c1f5f4db2b88ce'), 'name': 'Hallvard Lavik', 'age': 27}\n",
      "{'_id': ObjectId('68f9e59cd5c1f5f4db2b88cf'), 'name': 'Kristian', 'age': 31}\n",
      "{'_id': ObjectId('68f9e59cd5c1f5f4db2b88d0'), 'name': 'Ihn Duck', 'age': 19}\n",
      "{'_id': ObjectId('68f9eb80808542e48c46981a'), 'name': 'Hallvard Lavik', 'age': 26}\n",
      "{'_id': ObjectId('68f9eb80808542e48c46981b'), 'name': 'Kristian', 'age': 30}\n",
      "{'_id': ObjectId('68f9eb80808542e48c46981c'), 'name': 'Ihn Duck', 'age': 18}\n",
      "{'_id': ObjectId('68f9ef15613c6cb3688bb8f6'), 'name': 'Hallvard Lavik', 'age': 25}\n",
      "{'_id': ObjectId('68f9ef15613c6cb3688bb8f7'), 'name': 'Kristian', 'age': 29}\n",
      "{'_id': ObjectId('68f9ef15613c6cb3688bb8f8'), 'name': 'Ihn Duck', 'age': 17}\n",
      "{'_id': ObjectId('68f9f158307eef984fcb325a'), 'name': 'Hallvard Lavik', 'age': 24}\n",
      "{'_id': ObjectId('68f9f159307eef984fcb325b'), 'name': 'Kristian', 'age': 28}\n",
      "{'_id': ObjectId('68f9f159307eef984fcb325c'), 'name': 'Ihn Duck', 'age': 16}\n",
      "{'_id': ObjectId('68f9fe1aeec11bd59064fc54'), 'name': 'Hallvard', 'age': 23}\n",
      "{'_id': ObjectId('68f9fe1aeec11bd59064fc55'), 'name': 'Kristian', 'age': 27}\n",
      "{'_id': ObjectId('68f9fe1aeec11bd59064fc56'), 'name': 'Ihn Duck', 'age': 15}\n"
     ]
    }
   ],
   "source": [
    "# Reading ALL documents from a collection.\n",
    "# ........................................\n",
    "\n",
    "documents = collection.find({})\n",
    "# A cursor is returned.\n",
    "\n",
    "# The cursor can be iterated over:\n",
    "for document in documents:\n",
    "    print(document)\n",
    "\n",
    "# Or directly converted to a list:\n",
    "#documents = list(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13634bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('68f9fe1aeec11bd59064fc54'), 'name': 'Hallvard', 'age': 23}\n"
     ]
    }
   ],
   "source": [
    "# Reading SPECIFIC documents from a collection.\n",
    "# .............................................\n",
    "\n",
    "hallvard = collection.find({'name': 'Hallvard'})\n",
    "\n",
    "for document in hallvard:\n",
    "    print(document)\n",
    "\n",
    "hallvard = list(hallvard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd0aeee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x120379d7680>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updating a single document.\n",
    "# ...........................\n",
    "collection.update_one(\n",
    "    {'name': 'Hallvard'},\n",
    "    {'$set': {'name': 'Hallvard Lavik'}}  # Sets the `name` to `Hallvard Lavik`.\n",
    ")\n",
    "\n",
    "# Updating multiple documents.\n",
    "# ............................\n",
    "collection.update_many(\n",
    "    {},\n",
    "       {'$inc': {'age': 1}}  # Increments the `age` of all documents by `1`.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "378dabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "headers = {\n",
    "    \n",
    "}\n",
    "\n",
    "base_url = \"https://api.elhub.no/energy-data/v0/price-areas\"\n",
    "dataset = \"PRODUCTION_PER_GROUP_MBA_HOUR\"\n",
    "\n",
    "# Use timezone-aware datetime for Norwegian time zone\n",
    "oslo_tz = pytz.timezone('Europe/Oslo')\n",
    "start = oslo_tz.localize(datetime(2021, 1, 1, 0, 0, 0))\n",
    "end = oslo_tz.localize(datetime(2021, 12, 31, 23, 59, 59))\n",
    "\n",
    "responses = []\n",
    "\n",
    "while start <= end:\n",
    "    # Calculate month end in the same timezone\n",
    "    month_end = (start.replace(day=28) + timedelta(days=4)).replace(day=1) - timedelta(seconds=1)\n",
    "    if month_end > end:\n",
    "        month_end = end\n",
    "\n",
    "    params = {\n",
    "        \"dataset\": dataset,\n",
    "        \"startDate\": start.isoformat(),\n",
    "        \"endDate\": month_end.isoformat()\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, headers=headers, params=params)\n",
    "    responses.append(response.json())\n",
    "\n",
    "    start = month_end + timedelta(seconds=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4880b426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records extracted: 215353\n",
      "Sample record: {'endTime': '2021-01-01T01:00:00+01:00', 'lastUpdatedTime': '2024-12-20T10:35:40+01:00', 'priceArea': 'NO1', 'productionGroup': 'hydro', 'quantityKwh': 2507716.8, 'startTime': '2021-01-01T00:00:00+01:00'}\n"
     ]
    }
   ],
   "source": [
    "# Extract all productionPerGroupMbaHour lists from all responses\n",
    "all_production_data = []\n",
    "\n",
    "for response in responses:\n",
    "    # Navigate through the response structure\n",
    "    if 'data' in response:\n",
    "        for price_area in response['data']:\n",
    "            if 'attributes' in price_area and 'productionPerGroupMbaHour' in price_area['attributes']:\n",
    "                production_list = price_area['attributes']['productionPerGroupMbaHour']\n",
    "                # Only add non-empty lists\n",
    "                if production_list:\n",
    "                    all_production_data.extend(production_list)\n",
    "\n",
    "print(f\"Total records extracted: {len(all_production_data)}\")\n",
    "print(f\"Sample record: {all_production_data[0] if all_production_data else 'No data'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c67c4c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (215353, 6)\n",
      "\n",
      "DataFrame columns: ['endTime', 'lastUpdatedTime', 'priceArea', 'productionGroup', 'quantityKwh', 'startTime']\n",
      "\n",
      "First few rows:\n",
      "                     endTime            lastUpdatedTime priceArea  \\\n",
      "0  2021-01-01T01:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
      "1  2021-01-01T02:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
      "2  2021-01-01T03:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
      "3  2021-01-01T04:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
      "4  2021-01-01T05:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
      "\n",
      "  productionGroup  quantityKwh                  startTime  \n",
      "0           hydro    2507716.8  2021-01-01T00:00:00+01:00  \n",
      "1           hydro    2494728.0  2021-01-01T01:00:00+01:00  \n",
      "2           hydro    2486777.5  2021-01-01T02:00:00+01:00  \n",
      "3           hydro    2461176.0  2021-01-01T03:00:00+01:00  \n",
      "4           hydro    2466969.2  2021-01-01T04:00:00+01:00  \n"
     ]
    }
   ],
   "source": [
    "# Convert to pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(all_production_data)\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"\\nDataFrame columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8526cb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'production_data' created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create Cassandra table for production data\n",
    "session.execute(\"DROP TABLE IF EXISTS my_first_keyspace.production_data;\")\n",
    "\n",
    "# Create table with appropriate schema based on the data structure\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS my_first_keyspace.production_data (\n",
    "    price_area text,\n",
    "    production_group text,\n",
    "    start_time timestamp,\n",
    "    end_time timestamp,\n",
    "    quantity_kwh double,\n",
    "    last_updated_time timestamp,\n",
    "    PRIMARY KEY ((price_area, production_group), start_time)\n",
    ") WITH CLUSTERING ORDER BY (start_time ASC);\n",
    "\"\"\"\n",
    "\n",
    "session.execute(create_table_query)\n",
    "print(\"Table 'production_data' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "595c6df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark DataFrame schema:\n",
      "root\n",
      " |-- end_time: timestamp (nullable = true)\n",
      " |-- last_updated_time: timestamp (nullable = true)\n",
      " |-- price_area: string (nullable = true)\n",
      " |-- production_group: string (nullable = true)\n",
      " |-- quantity_kwh: double (nullable = true)\n",
      " |-- start_time: timestamp (nullable = true)\n",
      "\n",
      "\n",
      "Total rows: 215353\n",
      "\n",
      "First few rows:\n",
      "+-------------------+-------------------+----------+----------------+------------+-------------------+\n",
      "|end_time           |last_updated_time  |price_area|production_group|quantity_kwh|start_time         |\n",
      "+-------------------+-------------------+----------+----------------+------------+-------------------+\n",
      "|2021-01-01 01:00:00|2024-12-20 10:35:40|NO1       |hydro           |2507716.8   |2021-01-01 00:00:00|\n",
      "|2021-01-01 02:00:00|2024-12-20 10:35:40|NO1       |hydro           |2494728.0   |2021-01-01 01:00:00|\n",
      "|2021-01-01 03:00:00|2024-12-20 10:35:40|NO1       |hydro           |2486777.5   |2021-01-01 02:00:00|\n",
      "|2021-01-01 04:00:00|2024-12-20 10:35:40|NO1       |hydro           |2461176.0   |2021-01-01 03:00:00|\n",
      "|2021-01-01 05:00:00|2024-12-20 10:35:40|NO1       |hydro           |2466969.2   |2021-01-01 04:00:00|\n",
      "+-------------------+-------------------+----------+----------------+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrame to Spark DataFrame\n",
    "spark_df = spark.createDataFrame(df)\n",
    "\n",
    "# Rename columns to match Cassandra table schema (convert camelCase to snake_case)\n",
    "spark_df = spark_df.withColumnRenamed(\"priceArea\", \"price_area\") \\\n",
    "                   .withColumnRenamed(\"productionGroup\", \"production_group\") \\\n",
    "                   .withColumnRenamed(\"startTime\", \"start_time\") \\\n",
    "                   .withColumnRenamed(\"endTime\", \"end_time\") \\\n",
    "                   .withColumnRenamed(\"quantityKwh\", \"quantity_kwh\") \\\n",
    "                   .withColumnRenamed(\"lastUpdatedTime\", \"last_updated_time\")\n",
    "\n",
    "# Convert timestamp strings to timestamp type\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "spark_df = spark_df.withColumn(\"start_time\", to_timestamp(\"start_time\")) \\\n",
    "                   .withColumn(\"end_time\", to_timestamp(\"end_time\")) \\\n",
    "                   .withColumn(\"last_updated_time\", to_timestamp(\"last_updated_time\"))\n",
    "\n",
    "print(\"Spark DataFrame schema:\")\n",
    "spark_df.printSchema()\n",
    "print(f\"\\nTotal rows: {spark_df.count()}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "spark_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c9061d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully inserted into Cassandra!\n"
     ]
    }
   ],
   "source": [
    "# Insert data into Cassandra using Spark\n",
    "spark_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .options(table=\"production_data\", keyspace=\"my_first_keyspace\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"Data successfully inserted into Cassandra!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7105926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data from Cassandra:\n",
      "Row(price_area='NO3', production_group='wind', start_time=datetime.datetime(2020, 12, 31, 23, 0), end_time=datetime.datetime(2021, 1, 1, 0, 0), last_updated_time=datetime.datetime(2024, 12, 20, 9, 35, 40), quantity_kwh=259312.2)\n",
      "Row(price_area='NO3', production_group='wind', start_time=datetime.datetime(2021, 1, 1, 0, 0), end_time=datetime.datetime(2021, 1, 1, 1, 0), last_updated_time=datetime.datetime(2024, 12, 20, 9, 35, 40), quantity_kwh=225762.9)\n",
      "Row(price_area='NO3', production_group='wind', start_time=datetime.datetime(2021, 1, 1, 1, 0), end_time=datetime.datetime(2021, 1, 1, 2, 0), last_updated_time=datetime.datetime(2024, 12, 20, 9, 35, 40), quantity_kwh=248005.1)\n",
      "Row(price_area='NO3', production_group='wind', start_time=datetime.datetime(2021, 1, 1, 2, 0), end_time=datetime.datetime(2021, 1, 1, 3, 0), last_updated_time=datetime.datetime(2024, 12, 20, 9, 35, 40), quantity_kwh=243180.3)\n",
      "Row(price_area='NO3', production_group='wind', start_time=datetime.datetime(2021, 1, 1, 3, 0), end_time=datetime.datetime(2021, 1, 1, 4, 0), last_updated_time=datetime.datetime(2024, 12, 20, 9, 35, 40), quantity_kwh=250695.3)\n",
      "Row(price_area='NO3', production_group='wind', start_time=datetime.datetime(2021, 1, 1, 4, 0), end_time=datetime.datetime(2021, 1, 1, 5, 0), last_updated_time=datetime.datetime(2024, 12, 20, 9, 35, 40), quantity_kwh=272272.9)\n",
      "Row(price_area='NO3', production_group='wind', start_time=datetime.datetime(2021, 1, 1, 5, 0), end_time=datetime.datetime(2021, 1, 1, 6, 0), last_updated_time=datetime.datetime(2024, 12, 20, 9, 35, 40), quantity_kwh=247988.1)\n",
      "Row(price_area='NO3', production_group='wind', start_time=datetime.datetime(2021, 1, 1, 6, 0), end_time=datetime.datetime(2021, 1, 1, 7, 0), last_updated_time=datetime.datetime(2024, 12, 20, 9, 35, 40), quantity_kwh=224498.4)\n",
      "Row(price_area='NO3', production_group='wind', start_time=datetime.datetime(2021, 1, 1, 7, 0), end_time=datetime.datetime(2021, 1, 1, 8, 0), last_updated_time=datetime.datetime(2024, 12, 20, 9, 35, 40), quantity_kwh=212147.3)\n",
      "Row(price_area='NO3', production_group='wind', start_time=datetime.datetime(2021, 1, 1, 8, 0), end_time=datetime.datetime(2021, 1, 1, 9, 0), last_updated_time=datetime.datetime(2024, 12, 20, 9, 35, 40), quantity_kwh=185698.2)\n"
     ]
    }
   ],
   "source": [
    "# Verify the data was inserted by querying from Cassandra\n",
    "rows = session.execute(\"SELECT * FROM my_first_keyspace.production_data LIMIT 10;\")\n",
    "print(\"Sample data from Cassandra:\")\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
